#!/usr/bin/env python3
"""
Advanced Keyword Filter –¥–ª—è RSS Media Bus v3.1+
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from enum import Enum

logger = logging.getLogger(__name__)

class FilterMode(Enum):
    """–†–µ–∂–∏–º—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
    ALL = "all"                    # –í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
    INCLUDE = "include"            # –í–∫–ª—é—á–∏—Ç—å —Å—Ç–∞—Ç—å–∏ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    EXCLUDE = "exclude"            # –ò—Å–∫–ª—é—á–∏—Ç—å —Å—Ç–∞—Ç—å–∏ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    PRIORITY = "priority"          # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ + –æ–±—ã—á–Ω—ã–µ (—Å –ø–æ–º–µ—Ç–∫–∞–º–∏)
    SMART = "smart"                # –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è (ML –ø–æ–¥–æ–±–Ω–∞—è)

class KeywordMatcher:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º–∞—Ç—á–µ—Ä –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
    
    def __init__(self, keywords: List[str], case_sensitive: bool = False):
        self.keywords = keywords
        self.case_sensitive = case_sensitive
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Ä–µ–≥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.compiled_patterns = []
        for keyword in keywords:
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ wildcards: * –∏ ?
            if '*' in keyword or '?' in keyword:
                regex_pattern = keyword.replace('*', '.*').replace('?', '.')
                flags = 0 if case_sensitive else re.IGNORECASE
                self.compiled_patterns.append(re.compile(regex_pattern, flags))
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ (–≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤)
                escaped = re.escape(keyword)
                pattern = r'\b' + escaped + r'\b'
                flags = 0 if case_sensitive else re.IGNORECASE
                self.compiled_patterns.append(re.compile(pattern, flags))
    
    def find_matches(self, text: str) -> List[Tuple[str, int]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (keyword, count) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ"""
        matches = []
        text_to_search = text if self.case_sensitive else text.lower()
        
        for i, pattern in enumerate(self.compiled_patterns):
            keyword = self.keywords[i]
            found_matches = pattern.findall(text_to_search)
            if found_matches:
                matches.append((keyword, len(found_matches)))
        
        return matches
    
    def get_match_score(self, text: str) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–∏–π —Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        matches = self.find_matches(text)
        return sum(count for _, count in matches)

class AdvancedKeywordFilter:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        config format:
        {
            "mode": "include|exclude|priority|smart|all",
            "keywords": ["keyword1", "keyword2"],
            "min_matches": 1,
            "case_sensitive": false,
            "fields": ["title", "description", "content"],
            "priority_keywords": ["urgent", "breaking"],
            "exclude_keywords": ["spam", "advertisement"],
            "smart_categories": ["politics", "economy"],
            "boost_multiplier": 2.0
        }
        """
        self.mode = FilterMode(config.get('mode', 'all'))
        self.keywords = config.get('keywords', [])
        self.min_matches = config.get('min_matches', 1)
        self.case_sensitive = config.get('case_sensitive', False)
        self.fields = config.get('fields', ['title', 'description'])
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.priority_keywords = config.get('priority_keywords', [])
        self.exclude_keywords = config.get('exclude_keywords', [])
        self.smart_categories = config.get('smart_categories', [])
        self.boost_multiplier = config.get('boost_multiplier', 2.0)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—á–µ—Ä—ã
        self.main_matcher = KeywordMatcher(self.keywords, self.case_sensitive) if self.keywords else None
        self.priority_matcher = KeywordMatcher(self.priority_keywords, self.case_sensitive) if self.priority_keywords else None
        self.exclude_matcher = KeywordMatcher(self.exclude_keywords, self.case_sensitive) if self.exclude_keywords else None
        
        logger.info(f"üîç AdvancedKeywordFilter —Å–æ–∑–¥–∞–Ω: —Ä–µ–∂–∏–º={self.mode.value}, keywords={len(self.keywords)}")
    
    def filter_article(self, article: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç–∞—Ç—å—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (should_send, metadata)
        
        Returns:
            should_send: bool - –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏ —Å—Ç–∞—Ç—å—é
            metadata: dict - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏ —Ç.–¥.)
        """
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        article_text = self._extract_text(article)
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'filter_mode': self.mode.value,
            'matched_keywords': [],
            'priority_keywords': [],
            'excluded_keywords': [],
            'match_score': 0,
            'is_priority': False,
            'filter_reason': ''
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–∞—é—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if self.exclude_matcher:
            exclude_matches = self.exclude_matcher.find_matches(article_text)
            if exclude_matches:
                metadata['excluded_keywords'] = [kw for kw, _ in exclude_matches]
                metadata['filter_reason'] = f"–ò—Å–∫–ª—é—á–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {', '.join(metadata['excluded_keywords'])}"
                return False, metadata
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if self.mode == FilterMode.ALL:
            metadata['filter_reason'] = "–†–µ–∂–∏–º: –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏"
            return True, metadata
        
        elif self.mode == FilterMode.INCLUDE:
            return self._filter_include_mode(article_text, metadata)
        
        elif self.mode == FilterMode.EXCLUDE:
            return self._filter_exclude_mode(article_text, metadata)
        
        elif self.mode == FilterMode.PRIORITY:
            return self._filter_priority_mode(article_text, metadata)
        
        elif self.mode == FilterMode.SMART:
            return self._filter_smart_mode(article, article_text, metadata)
        
        else:
            metadata['filter_reason'] = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"
            return True, metadata
    
    def _extract_text(self, article: Dict[str, Any]) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π —Å—Ç–∞—Ç—å–∏"""
        text_parts = []
        
        for field in self.fields:
            if field in article and article[field]:
                text_parts.append(str(article[field]))
        
        return ' '.join(text_parts)
    
    def _filter_include_mode(self, text: str, metadata: Dict) -> Tuple[bool, Dict]:
        """–†–µ–∂–∏–º –≤–∫–ª—é—á–µ–Ω–∏—è: —Å—Ç–∞—Ç—å—è –ø—Ä–æ—Ö–æ–¥–∏—Ç –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        if not self.main_matcher:
            metadata['filter_reason'] = "–ù–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è"
            return True, metadata
        
        matches = self.main_matcher.find_matches(text)
        total_matches = sum(count for _, count in matches)
        
        metadata['matched_keywords'] = [kw for kw, _ in matches]
        metadata['match_score'] = total_matches
        
        if total_matches >= self.min_matches:
            metadata['filter_reason'] = f"–ù–∞–π–¥–µ–Ω–æ {total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {', '.join(metadata['matched_keywords'])}"
            return True, metadata
        else:
            metadata['filter_reason'] = f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matches} < {self.min_matches}"
            return False, metadata
    
    def _filter_exclude_mode(self, text: str, metadata: Dict) -> Tuple[bool, Dict]:
        """–†–µ–∂–∏–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è: —Å—Ç–∞—Ç—å—è –ù–ï –ø—Ä–æ—Ö–æ–¥–∏—Ç –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        if not self.main_matcher:
            metadata['filter_reason'] = "–ù–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è"
            return True, metadata
        
        matches = self.main_matcher.find_matches(text)
        total_matches = sum(count for _, count in matches)
        
        metadata['matched_keywords'] = [kw for kw, _ in matches]
        metadata['match_score'] = total_matches
        
        if total_matches >= self.min_matches:
            metadata['filter_reason'] = f"–ò—Å–∫–ª—é—á–µ–Ω–æ –ø–æ {total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º: {', '.join(metadata['matched_keywords'])}"
            return False, metadata
        else:
            metadata['filter_reason'] = f"–ù–µ—Ç –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"
            return True, metadata
    
    def _filter_priority_mode(self, text: str, metadata: Dict) -> Tuple[bool, Dict]:
        """–†–µ–∂–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ + –æ–±—ã—á–Ω—ã–µ —Å –ø–æ–º–µ—Ç–∫–∞–º–∏"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        priority_matches = []
        if self.priority_matcher:
            priority_matches = self.priority_matcher.find_matches(text)
            metadata['priority_keywords'] = [kw for kw, _ in priority_matches]
            metadata['is_priority'] = len(priority_matches) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        regular_matches = []
        if self.main_matcher:
            regular_matches = self.main_matcher.find_matches(text)
            metadata['matched_keywords'] = [kw for kw, _ in regular_matches]
        
        total_priority = sum(count for _, count in priority_matches)
        total_regular = sum(count for _, count in regular_matches)
        
        # Boost –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö
        metadata['match_score'] = total_regular + (total_priority * self.boost_multiplier)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ò–õ–ò –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—ã—á–Ω—ã—Ö
        if total_priority > 0:
            metadata['filter_reason'] = f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {', '.join(metadata['priority_keywords'])}"
            return True, metadata
        elif total_regular >= self.min_matches:
            metadata['filter_reason'] = f"–û–±—ã—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {', '.join(metadata['matched_keywords'])}"
            return True, metadata
        else:
            metadata['filter_reason'] = f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_regular} –æ–±—ã—á–Ω—ã—Ö, {total_priority} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö"
            return False, metadata
    
    def _filter_smart_mode(self, article: Dict, text: str, metadata: Dict) -> Tuple[bool, Dict]:
        """–£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        score = 0
        reasons = []
        
        # 1. –û–±—ã—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if self.main_matcher:
            matches = self.main_matcher.find_matches(text)
            keyword_score = sum(count for _, count in matches)
            score += keyword_score
            if matches:
                reasons.append(f"keywords: {keyword_score}")
                metadata['matched_keywords'] = [kw for kw, _ in matches]
        
        # 2. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if self.priority_matcher:
            priority_matches = self.priority_matcher.find_matches(text)
            priority_score = sum(count for _, count in priority_matches) * self.boost_multiplier
            score += priority_score
            if priority_matches:
                reasons.append(f"priority: {priority_score}")
                metadata['priority_keywords'] = [kw for kw, _ in priority_matches]
                metadata['is_priority'] = True
        
        # 3. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—Ç–∞—Ç—å–∏
        article_category = article.get('category', '').lower()
        if article_category in [cat.lower() for cat in self.smart_categories]:
            score += 5
            reasons.append(f"category: {article_category}")
        
        # 4. –ò—Å—Ç–æ—á–Ω–∏–∫ —Å—Ç–∞—Ç—å–∏ (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º–∏)
        source_id = article.get('feed_id', '')
        if source_id in ['tass.ru', 'ria.ru', 'reuters.com']:  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            score += 2
            reasons.append(f"priority_source: {source_id}")
        
        # 5. –í—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤–∞–∂–Ω–µ–µ)
        pub_date = article.get('published_date')
        if pub_date:
            hours_old = (datetime.now() - pub_date).total_seconds() / 3600
            if hours_old < 1:  # –ú–µ–Ω–µ–µ —á–∞—Å–∞
                score += 3
                reasons.append("fresh")
            elif hours_old < 6:  # –ú–µ–Ω–µ–µ 6 —á–∞—Å–æ–≤
                score += 1
                reasons.append("recent")
        
        metadata['match_score'] = score
        metadata['filter_reason'] = f"Smart score: {score} ({', '.join(reasons)})"
        
        # –£–º–Ω—ã–π –ø–æ—Ä–æ–≥ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–ª–∏—á–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        threshold = 3 if metadata.get('is_priority') else max(self.min_matches, 5)
        
        return score >= threshold, metadata

class FilterProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å User Notification Service"""
    
    def __init__(self, filter_configs: Dict[str, Dict[str, Any]]):
        """
        filter_configs: Dict[config_id, filter_config]
        –°–æ–∑–¥–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π telegram_config
        """
        self.filters = {}
        
        for config_id, filter_config in filter_configs.items():
            if filter_config:  # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                self.filters[config_id] = AdvancedKeywordFilter(filter_config)
                logger.info(f"‚úÖ –§–∏–ª—å—Ç—Ä —Å–æ–∑–¥–∞–Ω –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_id}")
            else:
                # –ù–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞ = –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ
                self.filters[config_id] = None
                logger.info(f"üì§ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è {config_id} –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–≤—Å–µ —Å—Ç–∞—Ç—å–∏)")
    
    def should_send_to_config(self, article: Dict[str, Any], config_id: str) -> Tuple[bool, Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å—Ç–∞—Ç—å—é –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        if config_id not in self.filters:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
            return True, {'filter_reason': 'No filter configured'}
        
        filter_instance = self.filters[config_id]
        if filter_instance is None:
            # –ù–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ
            return True, {'filter_reason': 'All articles mode'}
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
        return filter_instance.filter_article(article)

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
def create_simple_keyword_filter(keywords: List[str], mode: str = "include") -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ñ–∏–ª—å—Ç—Ä–∞"""
    return {
        "mode": mode,
        "keywords": keywords,
        "min_matches": 1,
        "case_sensitive": False,
        "fields": ["title", "description"]
    }

def create_priority_filter(normal_keywords: List[str], priority_keywords: List[str]) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞"""
    return {
        "mode": "priority",
        "keywords": normal_keywords,
        "priority_keywords": priority_keywords,
        "min_matches": 1,
        "case_sensitive": False,
        "fields": ["title", "description", "content"],
        "boost_multiplier": 3.0
    }

def create_smart_filter(categories: List[str], keywords: List[str] = None) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —É–º–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞"""
    return {
        "mode": "smart",
        "keywords": keywords or [],
        "smart_categories": categories,
        "min_matches": 2,
        "case_sensitive": False,
        "fields": ["title", "description", "content"],
        "boost_multiplier": 2.5
    }

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AdvancedKeywordFilter")
    
    # –¢–µ—Å—Ç–æ–≤–∞—è —Å—Ç–∞—Ç—å—è
    test_article = {
        'title': '–°—Ä–æ—á–Ω–æ: –ù–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ —Ü–∏—Ñ—Ä–æ–≤–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–µ –ø—Ä–∏–Ω—è—Ç',
        'description': '–ü–∞—Ä–ª–∞–º–µ–Ω—Ç –ø—Ä–∏–Ω—è–ª –≤–∞–∂–Ω—ã–π –∑–∞–∫–æ–Ω –æ —Ä–∞–∑–≤–∏—Ç–∏–∏ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –±–ª–æ–∫—á–µ–π–Ω',
        'content': '–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ –≤–∫–ª—é—á–∞—é—Ç —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –∏ NFT',
        'category': 'politics',
        'feed_id': 'tass.ru',
        'published_date': datetime.now()
    }
    
    # –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
    simple_config = create_simple_keyword_filter(['—Å—Ä–æ—á–Ω–æ', '–≤–∞–∂–Ω—ã–π', '–∑–∞–∫–æ–Ω'], 'include')
    simple_filter = AdvancedKeywordFilter(simple_config)
    
    should_send, metadata = simple_filter.filter_article(test_article)
    print(f"üìä –ü—Ä–æ—Å—Ç–æ–π —Ñ–∏–ª—å—Ç—Ä: {should_send}")
    print(f"   –ü—Ä–∏—á–∏–Ω–∞: {metadata['filter_reason']}")
    print(f"   –°–æ–≤–ø–∞–¥–µ–Ω–∏—è: {metadata['matched_keywords']}")
    
    # –¢–µ—Å—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
    priority_config = create_priority_filter(['–∑–∞–∫–æ–Ω', '—ç–∫–æ–Ω–æ–º–∏–∫–∞'], ['—Å—Ä–æ—á–Ω–æ', '–≤–∞–∂–Ω—ã–π'])
    priority_filter = AdvancedKeywordFilter(priority_config)
    
    should_send, metadata = priority_filter.filter_article(test_article)
    print(f"üìä –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: {should_send}")
    print(f"   –ü—Ä–∏—á–∏–Ω–∞: {metadata['filter_reason']}")
    print(f"   –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ: {metadata['priority_keywords']}")
    print(f"   –û–±—ã—á–Ω—ã–µ: {metadata['matched_keywords']}")
    
    # –¢–µ—Å—Ç —É–º–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
    smart_config = create_smart_filter(['politics', 'economy'], ['—Ü–∏—Ñ—Ä–æ–≤–æ–π', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'])
    smart_filter = AdvancedKeywordFilter(smart_config)
    
    should_send, metadata = smart_filter.filter_article(test_article)
    print(f"üìä –£–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: {should_send}")
    print(f"   –ü—Ä–∏—á–∏–Ω–∞: {metadata['filter_reason']}")
    print(f"   –°—á–µ—Ç: {metadata['match_score']}")
    print(f"   –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {metadata['is_priority']}") 